{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# layer1\n",
        "# -----------\n",
        "# KNN\n",
        "# LR\n",
        "# RF\n",
        "# XGB \n",
        "# NN\n",
        "\n",
        "# layer2\n",
        "# -----------\n",
        "# XGB\n",
        "# NN\n",
        "\n",
        "# -----------\n",
        "# avg(XGB+NN)\n"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "r5h_UgQmjUes",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import time\n",
        "import pickle\n",
        "import gc\n",
        "# import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,RandomizedSearchCV,GridSearchCV\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression,Ridge,Lasso\n",
        "from sklearn.metrics import *\n",
        "from sklearn.feature_selection import RFE, RFECV,VarianceThreshold, chi2\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, Normalizer \n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "# import catboost as cb\n",
        "# from catboost import Pool, CatBoostClassifier\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.regularizers import l1_l2"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 1,
      "metadata": {
        "id": "vRwL5e6HcLj6",
        "colab_type": "code",
        "outputId": "078da1fb-9a4d-44e7-d7db-23ef29b4ec0f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581192433879,
          "user_tz": -120,
          "elapsed": 3157,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helpers"
      ],
      "metadata": {
        "id": "zSe_2P6Aka2H",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Ctrl+ Shift + i` to `open` inspector view . Then goto console.\n",
        "\n",
        "```\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```"
      ],
      "metadata": {
        "id": "sqpfGBWJZoEC",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Gdrive method-1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "id": "trHN34qfZzOi",
        "colab_type": "code",
        "outputId": "bd43b3df-2fa6-4198-cfb9-f2d123a778e3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581192465874,
          "user_tz": -120,
          "elapsed": 27055,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f1_metric\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "# this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n",
        "\n",
        "\n",
        "def f1_metric(y_hat, y_true):\n",
        "    y_true = y_true.get_label()\n",
        "    preds = y_hat.reshape(4, -1).T\n",
        "    preds = preds.argmax(axis = 1)\n",
        "    return 'f1', f1_score(y_true, preds,  average='weighted'), True\n",
        "\n",
        "def auc_metric(y_hat, data):\n",
        "    y_true = data.get_label()\n",
        "    y_hat = np.round(y_hat)       # scikits f1 doesn't like probabilities\n",
        "    return 'f1', roc_auc_score(y_true, y_hat), True\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "_U4V5Op9Smf_",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM f1 metric\n",
        "\n",
        "def multi_class_f1_score_factory(num_classes, average):\n",
        "    \"\"\"Factory for LightGBM multi class F1-score function.\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_classes : int\n",
        "        Number of classes to classify.\n",
        "    average : string, 'micro' or 'macro'\n",
        "        ``'micro'``\n",
        "            Calculate metrics globally by counting the total true positives,\n",
        "            false negatives and false positives.\n",
        "        ``'macro'``\n",
        "            Calculate metrics for each label, and find their unweighted mean.\n",
        "            This does not take label imbalance into account.\n",
        "    \"\"\"\n",
        "    if average != 'macro' and average != 'micro':\n",
        "        raise ValueError(\"average should be 'macro' or 'micro'\")\n",
        "\n",
        "    eval_name = 'f1_' + average\n",
        "\n",
        "    def multi_class_f1_score(y_pred, data):\n",
        "        y_true = data.get_label()\n",
        "        y_pred = y_pred.reshape((num_classes, -1))\n",
        "        y_pred = np.transpose(y_pred)\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "        return eval_name, f1_score(y_true, y_pred, average=average), True\n",
        "\n",
        "    return multi_class_f1_score\n",
        "\n",
        "\n",
        "# feval=multi_class_f1_score_factory(num_classes, 'macro')"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "nP6xKP1Qzsyd",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_feature(X, tbl_lst = None, min_cnt = 1):\n",
        "    X_lst = [pd.Series(X[:, i]) for i in range(X.shape[1])]\n",
        "    if tbl_lst is None:\n",
        "        tbl_lst = [x.value_counts() for x in X_lst]\n",
        "        if min_cnt > 1:\n",
        "            tbl_lst = [s[s >= min_cnt] for s in tbl_lst]\n",
        "    X = sp.column_stack([x.map(tbl).values for x, tbl in zip(X_lst, tbl_lst)])\n",
        "    # NA(unseen values) to 0\n",
        "    return np.nan_to_num(X), tbl_lst\n",
        "\n",
        "def elapsed_time(start_time, end_time):\n",
        "    elapsed_sec = end_time - start_time\n",
        "    h = int(elapsed_sec / (60 * 60))\n",
        "    m = int((elapsed_sec % (60 * 60)) / 60)\n",
        "    s = int(elapsed_sec % 60)\n",
        "    return \"{}:{:>02}:{:>02}\".format(h, m, s)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "UKrG3fE8yGf2",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacking functions"
      ],
      "metadata": {
        "id": "o67Y-l1ix-Bc",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standarize_feature(train_df, test_df, cols):\n",
        "    scaler = StandardScaler()\n",
        "    for col in cols:\n",
        "        train_df[col] = scaler.fit_transform(train_df[col].values.reshape(-1,1).astype(np.float32))\n",
        "        test_df[col] = scaler.transform(test_df[col].values.reshape(-1,1).astype(np.float32))\n",
        "    return None\n",
        "\n",
        "def extend_bounds(bins):\n",
        "    bins[0] = bins[0] - 1\n",
        "    bins[-1] = bins[-1] + 1\n",
        "\n",
        "\n",
        "def discretize_feature(train_df, test_df, cols, num_bins, how='equal_freq'):\n",
        "    if how == 'equal_width':\n",
        "        for col in cols:\n",
        "            group_names = range(num_bins)\n",
        "            train_df[col], bins = pd.cut(train_df[col], num_bins, labels=group_names, retbins=True)\n",
        "            test_df[col] = pd.cut(test_df[col], bins, labels=group_names)\n",
        "    elif how == 'equal_freq':\n",
        "        for col in cols:\n",
        "            freq_per_bin = train_df[col].shape[0] / num_bins\n",
        "            values = sorted(train_df[col])\n",
        "            bins = [values[0]]\n",
        "            for i in range(1, num_bins + 1):\n",
        "                if i < num_bins:\n",
        "                    bins.append(values[i * freq_per_bin - 1])\n",
        "                else:\n",
        "                    bins.append(values[-1])\n",
        "            group_names = range(num_bins)\n",
        "\n",
        "            i = 1\n",
        "            while i < len(bins):\n",
        "                if bins[i] == bins[i-1]:\n",
        "                    del bins[i]\n",
        "                    del group_names[i]\n",
        "                else:\n",
        "                    i += 1\n",
        "            extend_bounds(bins)\n",
        "            train_df[col] = pd.cut(train_df[col], bins, labels=group_names)\n",
        "            test_df[col] = pd.cut(test_df[col], bins, labels=group_names)\n",
        "    return None"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "gc745PlwyB0W",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(train_df, test_df, ylabel='target', numerical_features=None, standarization=False, discretization=False, transform=None):\n",
        "    # numerical_features = train_df.columns\n",
        "\n",
        "    numerical_features = numerical_features\n",
        "    if standarization:\n",
        "        standarized_features = numerical_features\n",
        "        standarize_feature(train_df, test_df, standarized_features)\n",
        "        \n",
        "    if discretization:\n",
        "        discretized_features = numerical_features\n",
        "        discretize_feature(train_df, test_df, discretized_features, num_bins=10, how='equal_freq')\n",
        "    \n",
        "    X = train_df.drop(ylabel, axis=1).as_matrix()\n",
        "    y = train_df[ylabel].as_matrix()\n",
        "    X_submission = test_df.as_matrix()\n",
        "    \n",
        "    if transform == 'log':\n",
        "        X = np.log1p(X)\n",
        "        X_submission = np.log1p(X_submission)\n",
        "    elif transform == 'sqrt':\n",
        "        X = np.sqrt(X + 3.0 / 8)\n",
        "        X_submission = np.sqrt(X_submission + 3.0 / 8)\n",
        "    elif transform == 'pca':\n",
        "        pca = PCA(n_components=3).fit(X)\n",
        "        X = pca.transform(X)\n",
        "        X_submission = pca.transform(X_submission)\n",
        "    elif transform == 'tsne':\n",
        "        tsne = TSNE(n_components=3).fit(X)\n",
        "        X = tsne.transform(X)\n",
        "        X_submission = tsne.transform(X_submission)\n",
        "    elif transform == 'pca+':\n",
        "        pca = PCA(n_components=3).fit(X)\n",
        "        X = np.hstack((X, pca.transform(X)))\n",
        "        X_submission = np.hstack((X, pca.transform(X)))\n",
        "    elif transform == 'tsne+':\n",
        "        tsne = TSNE(n_components=3).fit(X)\n",
        "        X = np.hstack((X, tsne.transform(X)))\n",
        "        X_submission = np.hstack((X_submission, tsne.transform(X_submission)))        \n",
        "    return X, y, X_submission"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "XQMMj_TeyBzb",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y, y_pred):\n",
        "    mse = mean_squared_error(y, y_pred)\n",
        "    return mse"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "QeQARwZkyBwf",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def models_CV_train(models, X, y, X_submission, n_classes=1, n_folds=5):\n",
        "    summary = {}\n",
        "\n",
        "    kf = list(KFold(n_folds, random_state=42).split(X, y))\n",
        "    \n",
        "    stack_train = np.zeros((X.shape[0], n_classes, len(models)))\n",
        "    stack_test = np.zeros((X_submission.shape[0], n_classes, len(models)))\n",
        "    \n",
        "    for i, model in enumerate(models):\n",
        "        print(\"Model %d:\" % i, model)\n",
        "        \n",
        "        avg_logloss = 0\n",
        "        \n",
        "        stack_test_model_i = np.zeros((X_submission.shape[0], n_classes, len(skf)))\n",
        "        for j, (train_idx, test_idx) in enumerate(skf):\n",
        "            print(\"  Fold %d\" % j)\n",
        "            X_train = X[train_idx]\n",
        "            y_train = y[train_idx]\n",
        "            X_test = X[test_idx]\n",
        "            y_test = y[test_idx]\n",
        "\n",
        "            # if type(model) != dict:\n",
        "            #     model.fit(X_train, y_train)\n",
        "            #     y_test_pred = model.predict_proba(X_test)  \n",
        "            #     y_submission_pred = model.predict_proba(X_submission)   \n",
        "\n",
        "            # else:\n",
        "            #     print('Fit LightGBM model with early stopping.. \\n')\n",
        "            #     d_train = lgb.Dataset(X_train, y_train, categorical_feature=[7])  #categ_feats\n",
        "            #     d_eval = lgb.Dataset(X_test, y_test, categorical_feature=[6])     # categ_feats\n",
        "                \n",
        "            #     model = lgb.train(lgb_params, d_train, num_boost_round=1500, \n",
        "            #                        valid_sets=(d_train, d_eval), \n",
        "            #                        early_stopping_rounds=50,\n",
        "            #                        verbose_eval=200,\n",
        "            #                        feval=f1_metric,\n",
        "            #                        evals_result={} )\n",
        "\n",
        "            #     y_test_pred = model.predict(X_test)  #num_rounds=model.best_\n",
        "            #     y_submission_pred = model.predict(X_submission)      \n",
        "            \n",
        "            # elif type(model) == XGBClassifier:    # xgboost.sklearn.\n",
        "            #     print('Fit XGBOOST model with early stopping.. \\n')\n",
        "            #     d_train = xgb.DMatrix(X_train, y_train)  \n",
        "            #     d_test = xgb.DMatrix(X_test, y_test)     \n",
        "                \n",
        "            #     model = xgb.train(xgb_params, dtrain, num_boost_round=30, \n",
        "            #                       evals=[(d_train,'train'), (d_test,'eval')], obj=None,\n",
        "            #                       early_stopping_rounds=30, verbose_eval=200)\n",
        "                \n",
        "            #     y_test_pred = model.predict_proba(X_test)   # best_ntree_limit\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_test_pred = model.predict_proba(X_test)  \n",
        "\n",
        "            stack_train[test_idx, :, i] = y_test_pred\n",
        "            \n",
        "            score = evaluate(y_test, y_test_pred)\n",
        "            avg_score += score\n",
        "            print(\"logloss: %f\" % score)\n",
        "            \n",
        "            y_submission_pred = model.predict_proba(X_submission)           \n",
        "            stack_test_model_i[:, :, j] = y_submission_pred\n",
        "        \n",
        "        avg_score = avg_score / n_folds\n",
        "        print(\"model average logloss: %f\" % avg_score)\n",
        "        summary[i] = avg_score\n",
        "        \n",
        "        stack_test[:, :, i] = stack_test_model_i.mean(axis=2)\n",
        "\n",
        "    return np.swapaxes(stack_train, 1, 2).reshape((X.shape[0], -1)), np.swapaxes(stack_test, 1, 2).reshape((X_submission.shape[0], -1)), summary\n",
        "\n",
        "\n",
        "\n",
        "# rscv = RandomizedSearchCV(estimator=lgb_model, \n",
        "#                            param_distributions=hyperparams, \n",
        "#                            n_iter=30, \n",
        "#                            cv=kf, \n",
        "#                            scoring=SCORE,   \n",
        "#                            random_state=SEED, verbose=1, n_jobs=-1)\n",
        "\n",
        "# rscv.fit(data_train[feats], data_train[target])\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "tTWUp1_syBsX",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# d_train = lgb.Dataset(X_train, y_train, categorical_feature=[6])  #categ_feats\n",
        "# d_eval = lgb.Dataset(X_test, y_test, categorical_feature=[6])     # categ_feats\n",
        "                \n",
        "# lgb.train(lgb_params, d_train, num_boost_round=1500, \n",
        "#                                    valid_sets=(d_train, d_eval), \n",
        "#                                    early_stopping_rounds=50,\n",
        "#                                    verbose_eval=200,\n",
        "#                                    feval=f1_metric,\n",
        "#                                    evals_result={} )"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "kbJdOHoZkHLP",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stacking_models_CV_train(models, X, y, X_submission, n_classes=1, n_folds=5):\n",
        "\n",
        "    kf = list(KFold(n_folds, random_state=42).split(X, y))\n",
        "    \n",
        "    y_submission_pred = np.zeros((X_submission.shape[0], n_classes, len(models)))\n",
        "        \n",
        "    for i, model in enumerate(models):\n",
        "        print(\"Stacking Model %d\" % i, model)\n",
        "        avg_logloss = 0\n",
        "        y_submission_pred_model_i = np.zeros((X_submission.shape[0], n_classes, len(kf)))\n",
        "        for j, (train_idx, test_idx) in enumerate(skf):\n",
        "            print(\"Fold\", j)\n",
        "            X_train = X[train_idx]\n",
        "            y_train = y[train_idx]\n",
        "            X_test = X[test_idx]\n",
        "            y_test = y[test_idx]\n",
        "            \n",
        "            # model.fit(X_train, y_train)\n",
        "            \n",
        "            if type(model) == XGBClassifier:    \n",
        "                print('Fit XGBOOST model with early stopping.. \\n')\n",
        "                d_train = xgb.DMatrix(X_train, y_train)  \n",
        "                d_test = xgb.DMatrix(X_test, y_test)     \n",
        "                \n",
        "                model = xgb.train(xgb_params, dtrain, num_boost_round=30, \n",
        "                                  evals=[(d_train,'train'), (d_test,'eval')], obj=None,\n",
        "                                  early_stopping_rounds=30, verbose_eval=200)\n",
        "                \n",
        "            y_test_pred = model.predict_proba(X_test)   # best_ntree_limit\n",
        "            \n",
        "            y_submission_pred_model_i[:, :, j] = model.predict_proba(X_submission)\n",
        "            \n",
        "            score = evaluate(y_test, y_test_pred)\n",
        "            avg_score += score\n",
        "            print(\"  logloss: %f\" % score)\n",
        "\n",
        "        avg_score = avg_score / n_folds\n",
        "        print(\"model average logloss: %f\" % avg_score)\n",
        "\n",
        "        y_submission_pred[:, :, i] = y_submission_pred_model_i.mean(axis=2)\n",
        "\n",
        "    return y_submission_pred  \n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "CEz_KJG_yBpZ",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_2_layer_keras_model(input_dim, output_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.05, input_shape=(input_dim,)))\n",
        "    model.add(Dense(512, init='glorot_normal', activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-5)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, init='glorot_normal', activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-5)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(output_dim, init='glorot_normal', activation='softmax', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-5)))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])    # 'categorical_crossentropy'\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_3_layer_keras_model(input_dim, output_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.05, input_shape=(input_dim,)))\n",
        "    model.add(Dense(1024, init='glorot_normal', activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-5)))\n",
        "    model.add(Dropout(0.5))    \n",
        "    model.add(Dense(512, init='glorot_normal', activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-5)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, init='glorot_normal', activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-5)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(output_dim, init='glorot_normal', activation='softmax', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-5)))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])   # 'categorical_crossentropy'\n",
        "    return model\n",
        "\n",
        "\n",
        "# def create_nn_model(input_dim, output_dim=4):\n",
        "\n",
        "#     return model\n"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "MNLeVbn_yBm5",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # start_time = time.time()\n",
        "\n",
        "    # logging.basicConfig(level=logging.DEBUG,\n",
        "    #                     format='[%(asctime)s]: %(message)s ',\n",
        "    #                     datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    #                     stream=sys.stdout,\n",
        "    #                     filemode=\"w\"\n",
        "    #                     )\n",
        "\n",
        "    # load data\n",
        "    logging.info('Load data')\n",
        "    train_df, test_df = load_data(train_data_path='train.csv', test_data_path='test.csv')\n",
        "    X, y, X_submission = process_data(train_df, test_df, transform='sqrt')\n",
        "\n",
        "    # training phase 1\n",
        "    logging.info('Training phase 1')\n",
        "    models = []\n",
        "\n",
        "    # KNN\n",
        "    models += [KNeighborsClassifier(n_neighbors=2, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_neighbors=4, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_neighbors=8, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_neighbors=16, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_neighbors=32, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_neighbors=64, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_neighbors=128, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_neighbors=256, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_neighbors=512, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_neighbors=1024, n_jobs=-1)]\n",
        "\n",
        "    # Logistic Regression\n",
        "    models += [LogisticRegression(penalty='l1', solver='liblinear', n_jobs=-1, C=0.43, class_weight=None),\n",
        "               LogisticRegression(penalty='l2', solver='lbfgs', n_jobs=-1, C=0.01, class_weight=None, multi_class='multinomial')]\n",
        "\n",
        "    # Random Forest\n",
        "    models += [RandomForestClassifier(criterion='gini', n_jobs=-1, n_estimators=250, max_features=18, min_samples_split=5, max_depth=46, class_weight=None)]\n",
        "\n",
        "    # sklearn extra-trees classifier\n",
        "    models += [ExtraTreesClassifier(criterion='gini', n_estimators=500, n_jobs=-1)]\n",
        "\n",
        "    # xgboost\n",
        "    models += [XGBClassifier(base_score=0.5, colsample_bylevel=1,\n",
        "                             colsample_bytree=0.6, gamma=0,\n",
        "                             learning_rate=0.03, max_delta_step=0, max_depth=28,\n",
        "                             min_child_weight=6, n_estimators=2, nthread=-1,\n",
        "                             objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
        "                             scale_pos_weight=1, seed=0, silent=True, subsample=0.8)]\n",
        "\n",
        "    # NN\n",
        "    models += [KerasClassifier(build_fn=create_2_layer_keras_model, input_dim=93, output_dim=9, nb_epoch=100, batch_size=256, verbose=0),\n",
        "               KerasClassifier(build_fn=create_3_layer_keras_model, input_dim=93, output_dim=9, nb_epoch=100, batch_size=256, verbose=0)]\n",
        "\n",
        "    models += [KerasClassifier(build_fn=create_2_layer_keras_model, input_dim=X.shape[1], output_dim=9, nb_epoch=100, batch_size=256, verbose=0)]\n",
        "\n",
        "    logging.info('List of models to train and ensemble:')\n",
        "    for model in models:\n",
        "        print model\n",
        "    num_models = len(models)\n",
        "\n",
        "    train_models_pred, test_models_pred, summary = models_CV_train(models, X, y, X_submission, n_classes=9, n_folds=5)\n",
        "    # save phase 1 intermediate prediction results\n",
        "    # np.savetxt('train_models_pred.csv', train_models_pred)\n",
        "    # np.savetxt('test_models_pred.csv', test_models_pred)\n",
        "\n",
        "    logging.info('Summary for phase 1 model performance:')\n",
        "    for i in sorted(summary.keys()):\n",
        "        print 'Model %d: %f' % (i, summary[i])\n",
        "\n",
        "    # training phase 2\n",
        "    logging.info('Training phase 2: stacking model predictions from phase 1')\n",
        "    stacking_models = []\n",
        "\n",
        "    # stacking models' predictions using xgboost\n",
        "    stacking_models +=[XGBClassifier(base_score=0.5, colsample_bylevel=1,\n",
        "                                     colsample_bytree=0.6, gamma=0,\n",
        "                                     learning_rate=0.03, max_delta_step=0, max_depth=90,\n",
        "                                     min_child_weight=6, n_estimators=500, nthread=-1,\n",
        "                                     objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
        "                                     scale_pos_weight=1, seed=0, silent=True, subsample=0.8)]\n",
        "\n",
        "    # stacking models' predictions using NN\n",
        "    stacking_models += [KerasClassifier(build_fn=create_2_layer_keras_model, input_dim=num_models * 9, output_dim=9, nb_epoch=2, batch_size=256, verbose=0)]\n",
        "\n",
        "    y_submission_pred = stacking_models_CV_train(stacking_models, train_models_pred, y, test_models_pred, n_classes=9, n_folds=5)\n",
        "    y_submission_pred = y_submission_pred.mean(axis=2)\n",
        "\n",
        "    # write submission\n",
        "    logging.info(\"Write submission: averaging stacking models' predictions\")\n",
        "    timestamp = time.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "    columns = ['Class_' + str(i + 1) for i in range(9)]\n",
        "    submission_df = pd.DataFrame(y_submission_pred, columns=columns)\n",
        "    submission_df.index = submission_df.index + 1\n",
        "    submission_df.to_csv('submission_%s.csv' % timestamp, sep=',', index_label='id')\n",
        "    \n",
        "    end_time = time.time()\n",
        "    logging.info(\"Run complete: %s elapsed\" % elapsed_time(start_time, end_time))"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "n79UAw1QyBjM",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "-touNpp_UkkT",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Highlights of the dataset`\n",
        "\n",
        "```\n",
        "Accident_ID:                unique id assigned to each row\n",
        "Accident_Type_Code:           the type of accident (factor, not numeric)\n",
        "Cabin_Temperature:            the last recorded temperature before the incident, measured in degrees fahrenheit\n",
        "Turbulence_In_gforces:      the recorded/estimated turbulence experienced during the accident\n",
        "Control_Metric:               an estimation of how much control the pilot had during the incident given the factors at play\n",
        "Total_Safety_Complaints:     number of complaints from mechanics prior to the accident\n",
        "Days_Since_Inspection:        how long the plane went without inspection before the incident\n",
        "Safety_Score:                 a measure of how safe the plane was deemed to be\n",
        "Severity:                    a description (4 level factor) on the severity of the crash [Target]\n",
        "```"
      ],
      "metadata": {
        "id": "_T3fm6zHlQbW",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLAB = True \n",
        "LOAD_DATASET = False\n",
        "\n",
        "if COLAB:\n",
        "  data_path = '/content/gdrive/My Drive/ML Projects/Hacker/data/'\n",
        "  models_path = '/content/gdrive/My Drive/ML Projects/Hacker/models/'\n",
        "  out_path = '/content/gdrive/My Drive/ML Projects/Hacker/'\n",
        "else:\n",
        "  data_path = '/home/ime/Documents/PyCharmProjects/AV/LTFS/data/'\n",
        "  models_path = '/home/ime/Documents/PyCharmProjects/AV/LTFS/models/'\n",
        "  out_path = '/home/ime/Documents/PycharmProjects/AV/LTFS/submissions/'"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "BSpNSfOnZ3fg",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_map = {\n",
        "    'Minor_Damage_And_Injuries': 0,\n",
        "    'Significant_Damage_And_Fatalities': 1,\n",
        "    'Significant_Damage_And_Serious_Injuries': 2,\n",
        "    'Highly_Fatal_And_Damaging': 3}\n",
        "\n",
        "inverse_class_map = {\n",
        "    0: 'Minor_Damage_And_Injuries',\n",
        "    1: 'Significant_Damage_And_Fatalities',\n",
        "    2: 'Significant_Damage_And_Serious_Injuries',\n",
        "    3: 'Highly_Fatal_And_Damaging'}\n"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "7dDS0ZBq2Ikz",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(train_data_path=data_path+'train.csv', test_data_path=data_path+'test.csv'):\n",
        "\n",
        "    train_df = pd.read_csv(train_data_path)\n",
        "    test_df = pd.read_csv(test_data_path)\n",
        "    \n",
        "    train_df['Severity'] = train_df['Severity'].map(class_map).astype(np.uint8)\n",
        "        \n",
        "    return train_df, test_df"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "9Y7pKD7dyT-N",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if LOAD_DATASET:\n",
        "#     # load processed data NN\n",
        "#     data_train = pd.read_csv(data_path+'train_dataset_ml_18f_v2.csv')\n",
        "#     data_test = pd.read_csv(data_path+'test_dataset_ml_18f_v2.csv')\n",
        "# else: \n",
        "#     # load raw data\n",
        "#     data_train = pd.read_csv(data_path+'train.csv')\n",
        "#     data_test = pd.read_csv(data_path+'test.csv')\n",
        "#     # subm_file = pd.read_csv(data_path+'sample_submission.csv')\n",
        "\n",
        "train_df, test_df = load_data()\n",
        "\n",
        "print (\"Shape of Training Data:{}\".format(train_df.shape))\n",
        "print (\"Shape of Testing Data:{}\".format(test_df.shape))\n",
        "\n",
        "print(train_df['Severity'].value_counts(normalize=True))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training Data:(10000, 12)\n",
            "Shape of Testing Data:(2500, 11)\n",
            "3    0.3049\n",
            "2    0.2729\n",
            "0    0.2527\n",
            "1    0.1695\n",
            "Name: Severity, dtype: float64\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "id": "bRb3nYFbcYCy",
        "colab_type": "code",
        "outputId": "96a3a4a6-6cba-473f-fa7a-df270ca7c652",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581193687121,
          "user_tz": -120,
          "elapsed": 1772,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Severity</th>\n",
              "      <th>Safety_Score</th>\n",
              "      <th>Days_Since_Inspection</th>\n",
              "      <th>Total_Safety_Complaints</th>\n",
              "      <th>Control_Metric</th>\n",
              "      <th>Turbulence_In_gforces</th>\n",
              "      <th>Cabin_Temperature</th>\n",
              "      <th>Accident_Type_Code</th>\n",
              "      <th>Max_Elevation</th>\n",
              "      <th>Violations</th>\n",
              "      <th>Adverse_Weather_Metric</th>\n",
              "      <th>Accident_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>49.223744</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>71.285324</td>\n",
              "      <td>0.272118</td>\n",
              "      <td>78.04</td>\n",
              "      <td>2</td>\n",
              "      <td>31335.476824</td>\n",
              "      <td>3</td>\n",
              "      <td>0.424352</td>\n",
              "      <td>7570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>62.465753</td>\n",
              "      <td>10</td>\n",
              "      <td>27</td>\n",
              "      <td>72.288058</td>\n",
              "      <td>0.423939</td>\n",
              "      <td>84.54</td>\n",
              "      <td>2</td>\n",
              "      <td>26024.711057</td>\n",
              "      <td>2</td>\n",
              "      <td>0.352350</td>\n",
              "      <td>12128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>63.059361</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>66.362808</td>\n",
              "      <td>0.322604</td>\n",
              "      <td>78.86</td>\n",
              "      <td>7</td>\n",
              "      <td>39269.053927</td>\n",
              "      <td>3</td>\n",
              "      <td>0.003364</td>\n",
              "      <td>2181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>48.082192</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>74.703737</td>\n",
              "      <td>0.337029</td>\n",
              "      <td>81.79</td>\n",
              "      <td>3</td>\n",
              "      <td>42771.499200</td>\n",
              "      <td>1</td>\n",
              "      <td>0.211728</td>\n",
              "      <td>5946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>26.484018</td>\n",
              "      <td>13</td>\n",
              "      <td>25</td>\n",
              "      <td>47.948952</td>\n",
              "      <td>0.541140</td>\n",
              "      <td>77.16</td>\n",
              "      <td>3</td>\n",
              "      <td>35509.228515</td>\n",
              "      <td>2</td>\n",
              "      <td>0.176883</td>\n",
              "      <td>9054</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Severity  Safety_Score  ...  Adverse_Weather_Metric  Accident_ID\n",
              "0         0     49.223744  ...                0.424352         7570\n",
              "1         0     62.465753  ...                0.352350        12128\n",
              "2         1     63.059361  ...                0.003364         2181\n",
              "3         2     48.082192  ...                0.211728         5946\n",
              "4         1     26.484018  ...                0.176883         9054\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 17,
      "metadata": {
        "id": "lA5ZMi4yk9on",
        "colab_type": "code",
        "outputId": "7df3072e-d1e7-494d-b54f-e63f1750ed5b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581193727656,
          "user_tz": -120,
          "elapsed": 1141,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Safety_Score</th>\n",
              "      <th>Days_Since_Inspection</th>\n",
              "      <th>Total_Safety_Complaints</th>\n",
              "      <th>Control_Metric</th>\n",
              "      <th>Turbulence_In_gforces</th>\n",
              "      <th>Cabin_Temperature</th>\n",
              "      <th>Accident_Type_Code</th>\n",
              "      <th>Max_Elevation</th>\n",
              "      <th>Violations</th>\n",
              "      <th>Adverse_Weather_Metric</th>\n",
              "      <th>Accident_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.497717</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>72.151322</td>\n",
              "      <td>0.388959</td>\n",
              "      <td>78.32</td>\n",
              "      <td>4</td>\n",
              "      <td>37949.724386</td>\n",
              "      <td>2</td>\n",
              "      <td>0.069692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58.173516</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>64.585232</td>\n",
              "      <td>0.250841</td>\n",
              "      <td>78.60</td>\n",
              "      <td>7</td>\n",
              "      <td>30194.805567</td>\n",
              "      <td>2</td>\n",
              "      <td>0.002777</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33.287671</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>64.721969</td>\n",
              "      <td>0.336669</td>\n",
              "      <td>86.96</td>\n",
              "      <td>6</td>\n",
              "      <td>17572.925484</td>\n",
              "      <td>1</td>\n",
              "      <td>0.004316</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.287671</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>66.362808</td>\n",
              "      <td>0.421775</td>\n",
              "      <td>80.86</td>\n",
              "      <td>3</td>\n",
              "      <td>40209.186341</td>\n",
              "      <td>2</td>\n",
              "      <td>0.199990</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.867580</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>56.107566</td>\n",
              "      <td>0.313228</td>\n",
              "      <td>79.22</td>\n",
              "      <td>2</td>\n",
              "      <td>35495.525408</td>\n",
              "      <td>2</td>\n",
              "      <td>0.483696</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Safety_Score  Days_Since_Inspection  ...  Adverse_Weather_Metric  Accident_ID\n",
              "0     19.497717                     16  ...                0.069692            1\n",
              "1     58.173516                     15  ...                0.002777           10\n",
              "2     33.287671                     15  ...                0.004316           14\n",
              "3      3.287671                     21  ...                0.199990           17\n",
              "4     10.867580                     18  ...                0.483696           21\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 0,
      "metadata": {
        "id": "tm8FK2Vmk9t5",
        "colab_type": "code",
        "outputId": "b48bf30f-5e3e-4781-87ef-858afba9cdcc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581155539208,
          "user_tz": -120,
          "elapsed": 1163,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process data"
      ],
      "metadata": {
        "id": "QcTlh8IB1_37",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [train_df, test_df]:\n",
        "    df = df.drop(['Accident_ID'], axis=1, inplace=True)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "qCoS4maCfdpd",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dtypes, test_df.dtypes"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": [
              "(Severity                     uint8\n",
              " Safety_Score               float64\n",
              " Days_Since_Inspection        int64\n",
              " Total_Safety_Complaints      int64\n",
              " Control_Metric             float64\n",
              " Turbulence_In_gforces      float64\n",
              " Cabin_Temperature          float64\n",
              " Accident_Type_Code           int64\n",
              " Max_Elevation              float64\n",
              " Violations                   int64\n",
              " Adverse_Weather_Metric     float64\n",
              " dtype: object, Safety_Score               float64\n",
              " Days_Since_Inspection        int64\n",
              " Total_Safety_Complaints      int64\n",
              " Control_Metric             float64\n",
              " Turbulence_In_gforces      float64\n",
              " Cabin_Temperature          float64\n",
              " Accident_Type_Code           int64\n",
              " Max_Elevation              float64\n",
              " Violations                   int64\n",
              " Adverse_Weather_Metric     float64\n",
              " dtype: object)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 22,
      "metadata": {
        "id": "HtJmXnIOmedh",
        "colab_type": "code",
        "outputId": "929d3311-31d4-41da-c2b4-4d81960aa7d5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581193847132,
          "user_tz": -120,
          "elapsed": 1116,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select features\n",
        "num_feats = [col for col in train_df.columns if train_df[col].dtype in ['float64'] ]\n",
        "\n",
        "# select categorical features\n",
        "categ_feats = ['Accident_Type_Code']\n",
        "\n",
        "print('# num features: ', len(num_feats), len(train_df.columns))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# num features:  6 11\n"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {
        "id": "DLOpfFY3kgl2",
        "colab_type": "code",
        "outputId": "e7def512-5974-4827-cc99-6b0fd9384812",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581193867287,
          "user_tz": -120,
          "elapsed": 1160,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, X_submission = process_data(train_df, test_df, \n",
        "                                                    ylabel='Severity', \n",
        "                                                    numerical_features = num_feats,\n",
        "                                                    standarization=True, \n",
        "                                                    discretization=False, \n",
        "                                                    transform=None \n",
        "                                  )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "id": "uwDsLNLUMT_c",
        "colab_type": "code",
        "outputId": "f8dc8a71-dc7d-424d-af01-1c7e2520b4c6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581193904470,
          "user_tz": -120,
          "elapsed": 1112,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape, X_submission.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": [
              "((10000, 10), (10000,), (2500, 10))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 27,
      "metadata": {
        "id": "ksIWt6hLnlzm",
        "colab_type": "code",
        "outputId": "0cf9b37c-745c-4c5d-8236-3f0c6113ee9b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581193909670,
          "user_tz": -120,
          "elapsed": 1204,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training phase 1"
      ],
      "metadata": {
        "id": "dvttokYD0pr4",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "\n",
        "# # KNN\n",
        "# models += [\n",
        "#         #    KNeighborsClassifier(n_neighbors=2, n_jobs=-1),\n",
        "#         #    KNeighborsClassifier(n_neighbors=4, n_jobs=-1, p=2),\n",
        "#         #    KNeighborsClassifier(n_neighbors=8, n_jobs=-1, p=1),\n",
        "#         #    KNeighborsClassifier(n_neighbors=16, n_jobs=-1, p=2),\n",
        "#         #    KNeighborsClassifier(n_neighbors=32, n_jobs=-1),\n",
        "#         #    KNeighborsClassifier(n_neighbors=64, n_jobs=-1, p=2),\n",
        "#         #    KNeighborsClassifier(n_neighbors=128, n_jobs=-1, p=2),\n",
        "#            KNeighborsClassifier(n_neighbors=256, n_jobs=-1, p=2),\n",
        "#            KNeighborsClassifier(n_neighbors=512, n_jobs=-1, p=2),\n",
        "#         #    KNeighborsClassifier(n_neighbors=1024, n_jobs=-1)\n",
        "#            ]\n",
        "\n",
        "# Logistic Regression\n",
        "# models += [\n",
        "#            LogisticRegression(penalty='l1', solver='liblinear', n_jobs=-1, C=0.1, class_weight=None),\n",
        "#         #    LogisticRegression(penalty='l2', solver='lbfgs', n_jobs=-1, C=0.01, class_weight='balanced', multi_class='multinomial')\n",
        "#            ]\n",
        "\n",
        "# Random Forest\n",
        "models += [\n",
        "        RandomForestClassifier(criterion='gini', n_jobs=-1, n_estimators=300, \n",
        "                                  max_features='sqrt', min_samples_split=10, max_depth=46, \n",
        "                                  class_weight=None, bootstrap=False),\n",
        "        RandomForestClassifier(criterion='gini', n_jobs=-1, n_estimators=700, \n",
        "                                  max_features='sqrt', max_depth=None, \n",
        "                                  class_weight='balanced')]\n",
        "\n",
        "\n",
        "# Extra-trees classifier\n",
        "# models += [ExtraTreesClassifier(criterion='gini', n_estimators=300, n_jobs=-1)]\n",
        "\n",
        "# XGBoost\n",
        "models += [XGBClassifier(base_score=0.5, colsample_bylevel=1,\n",
        "                          subsample=0.9,\n",
        "                             colsample_bytree=0.6, gamma=0,\n",
        "                             learning_rate=0.03, max_delta_step=0, max_depth=7,\n",
        "                             min_child_weight=6, n_estimators=1100, nthread=-1,\n",
        "                             objective='multi:softprob', reg_alpha=1.0, reg_lambda=2.0),\n",
        "            XGBClassifier(base_score=0.5, colsample_bylevel=1,colsample_bytree=0.8,\n",
        "                          subsample=0.95, gamma=0, objective='multi:softprob',\n",
        "                             learning_rate=0.03, max_delta_step=0, max_depth=7,\n",
        "                             min_child_weight=6, n_estimators=900, nthread=-1,\n",
        "                             reg_alpha=1.0, reg_lambda=1.5) ]\n",
        "\n",
        "\n",
        "# XGB best params:\n",
        "#  {'subsample': 0.9, 'n_estimators': 1300, 'max_depth': 7, 'learning_rate': 0.1}\n",
        "# XGB best_score 0.956784\n",
        "\n",
        "\n",
        "# LGBM \n",
        "# LGBM best params:\n",
        "#  {'subsample': 0.4, 'num_leaves': 128, 'num_iterations': 700, 'max_depth': 9, 'learning_rate': 0.2, 'feature_fraction': 0.8}\n",
        "# best_score 0.9669990951908287\n",
        "\n",
        "# LGBM best params:\n",
        "#  {'subsample': 0.9, 'num_leaves': 16, 'num_iterations': 800, 'max_depth': 9, 'learning_rate': 0.1, 'feature_fraction': 0.9}\n",
        "# LGBM best_score 0.956765\n",
        "\n",
        "lgb_params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': 4,\n",
        "    'eval_metric': {'multi_logloss'},     # 'multi_logloss',    # 'multi_logloss' 'auc',  'f1', 'f1_macro', 'f1_micro', \n",
        "    'subsample': 0.4,\n",
        "    # 'subsample_freq': 1,\n",
        "    'learning_rate': 0.2,\n",
        "    'num_iterations': 700,\n",
        "    'num_leaves': 128,\n",
        "    'feature_fraction': 0.8,\n",
        "    'max_depth': 9,\n",
        "    'lambda_l1': 1.5,\n",
        "    'lambda_l2': 2.5 }\n",
        "\n",
        "\n",
        "models += [ lgb.LGBMClassifier(**lgb_params) ]\n",
        "\n",
        "\n",
        "# NN\n",
        "# models += [\n",
        "#            KerasClassifier(build_fn=create_2_layer_keras_model, input_dim=X.shape[1], output_dim=4, nb_epoch=100, batch_size=256, verbose=0),\n",
        "#            KerasClassifier(build_fn=create_3_layer_keras_model, input_dim=X.shape[1], output_dim=4, nb_epoch=100, batch_size=256, verbose=0)]\n",
        "\n",
        "# models += [KerasClassifier(build_fn=create_2_layer_keras_model, input_dim=X.shape[1], output_dim=4, nb_epoch=100, batch_size=256, verbose=0)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('List of models to train and ensemble:')\n",
        "for model in models:\n",
        "    print(model)\n",
        "    num_models = len(models)\n",
        "print('# base models:', num_models)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of models to train and ensemble:\n",
            "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=46, max_features='sqrt',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=10,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
            "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
            "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n",
            "              learning_rate=0.03, max_delta_step=0, max_depth=7,\n",
            "              min_child_weight=6, missing=None, n_estimators=1100, n_jobs=1,\n",
            "              nthread=-1, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=1.0, reg_lambda=2.0, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.9, verbosity=1)\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
            "              learning_rate=0.03, max_delta_step=0, max_depth=7,\n",
            "              min_child_weight=6, missing=None, n_estimators=900, n_jobs=1,\n",
            "              nthread=-1, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=1.0, reg_lambda=1.5, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.95, verbosity=1)\n",
            "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
            "               eval_metric={'multi_logloss'}, feature_fraction=0.8,\n",
            "               importance_type='split', lambda_l1=1.5, lambda_l2=2.5,\n",
            "               learning_rate=0.2, max_depth=9, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_class=4, num_iterations=700, num_leaves=128,\n",
            "               objective='multiclass', random_state=None, reg_alpha=0.0,\n",
            "               reg_lambda=0.0, silent=True, subsample=0.4,\n",
            "               subsample_for_bin=200000, subsample_freq=0)\n",
            "# base models: 5\n"
          ]
        }
      ],
      "execution_count": 70,
      "metadata": {
        "id": "6Ml0YwWD0sYo",
        "colab_type": "code",
        "outputId": "03e3c2ce-8fb0-4a57-e765-a4e402687ba0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581197649655,
          "user_tz": -120,
          "elapsed": 1226,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in models:\n",
        "    print(type(i))\n",
        "\n",
        "# type(models[2]) == XGBClassifier   \n",
        "\n",
        "# models[5].fit()\n",
        "\n",
        "# xgb.XGBClassifier().fit(X, )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
            "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
            "<class 'xgboost.sklearn.XGBClassifier'>\n",
            "<class 'xgboost.sklearn.XGBClassifier'>\n",
            "<class 'lightgbm.sklearn.LGBMClassifier'>\n"
          ]
        }
      ],
      "execution_count": 73,
      "metadata": {
        "id": "hvA4XM7XgrUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1ee2ea3a-44a8-475e-b21e-926adfd63879",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581197796090,
          "user_tz": -120,
          "elapsed": 1826,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time1 = time.time()\n",
        "\n",
        "train_models_pred, test_models_pred, summary = models_CV_train(models, X, y, X_submission, n_classes=4, n_folds=5)\n",
        "\n",
        "print('='*10)\n",
        "print('Training phase 1 elapsed time:', start_time1 - time.time(), '[sec]')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 0: RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=46, max_features='sqrt',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=10,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
            "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "  Fold 0\n",
            "logloss: 0.311254\n",
            "  Fold 1\n",
            "logloss: 0.307694\n",
            "  Fold 2\n",
            "logloss: 0.297337\n",
            "  Fold 3\n",
            "logloss: 0.298472\n",
            "  Fold 4\n",
            "logloss: 0.292852\n",
            "model average logloss: 0.301522\n",
            "Model 1: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
            "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "  Fold 0\n",
            "logloss: 0.328816\n",
            "  Fold 1\n",
            "logloss: 0.324685\n",
            "  Fold 2\n",
            "logloss: 0.313836\n",
            "  Fold 3\n",
            "logloss: 0.309871\n",
            "  Fold 4\n",
            "logloss: 0.308352\n",
            "model average logloss: 0.317112\n",
            "Model 2: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n",
            "              learning_rate=0.03, max_delta_step=0, max_depth=7,\n",
            "              min_child_weight=6, missing=None, n_estimators=1100, n_jobs=1,\n",
            "              nthread=-1, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=1.0, reg_lambda=2.0, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.9, verbosity=1)\n",
            "  Fold 0\n",
            "logloss: 0.148677\n",
            "  Fold 1\n",
            "logloss: 0.145491\n",
            "  Fold 2\n",
            "logloss: 0.141588\n",
            "  Fold 3\n",
            "logloss: 0.137928\n",
            "  Fold 4\n",
            "logloss: 0.122311\n",
            "model average logloss: 0.139199\n",
            "Model 3: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
            "              learning_rate=0.03, max_delta_step=0, max_depth=7,\n",
            "              min_child_weight=6, missing=None, n_estimators=900, n_jobs=1,\n",
            "              nthread=-1, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=1.0, reg_lambda=1.5, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.95, verbosity=1)\n",
            "  Fold 0\n",
            "logloss: 0.144707\n",
            "  Fold 1\n",
            "logloss: 0.140088\n",
            "  Fold 2\n",
            "logloss: 0.135785\n",
            "  Fold 3\n",
            "logloss: 0.133297\n",
            "  Fold 4\n",
            "logloss: 0.113179\n",
            "model average logloss: 0.133411\n",
            "Model 4: LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
            "               eval_metric={'multi_logloss'}, feature_fraction=0.8,\n",
            "               importance_type='split', lambda_l1=1.5, lambda_l2=2.5,\n",
            "               learning_rate=0.2, max_depth=9, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_class=4, num_iterations=700, num_leaves=128,\n",
            "               objective='multiclass', random_state=None, reg_alpha=0.0,\n",
            "               reg_lambda=0.0, silent=True, subsample=0.4,\n",
            "               subsample_for_bin=200000, subsample_freq=0)\n",
            "  Fold 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.151244\n",
            "  Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.147962\n",
            "  Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.148249\n",
            "  Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.140030\n",
            "  Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.114747\n",
            "model average logloss: 0.140446\n"
          ]
        }
      ],
      "execution_count": 74,
      "metadata": {
        "id": "p-0hctWy0seX",
        "colab_type": "code",
        "outputId": "e18954f9-92c6-41ab-a9b1-64dbdd1ec85b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198137503,
          "user_tz": -120,
          "elapsed": 324875,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save phase 1 intermediate prediction results\n",
        "np.savetxt(data_path+'train_models_pred_3.csv', train_models_pred)\n",
        "np.savetxt(data_path+'test_models_pred_3.csv', test_models_pred)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "SmpkoVKk0spE",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_models_pred.shape, test_models_pred.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 76,
          "data": {
            "text/plain": [
              "((10000, 20), (2500, 20))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 76,
      "metadata": {
        "id": "UJ15BOEAQ9TY",
        "colab_type": "code",
        "outputId": "e5b29b87-bab4-4500-eb69-70c857ee475a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198160576,
          "user_tz": -120,
          "elapsed": 590,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(models_path+'base_models_3.pickle', 'wb') as f:\n",
        "    pickle.dump(obj=models, file=f)\n",
        "\n",
        "# RandomForestClassifier   ->\n",
        "# RandomForestClassifier   ->\n",
        "# XGBClassifier'   ->\n",
        "# XGBClassifier'   ->\n",
        "# LGBM             -> "
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "Mvakm9Tr4lMf",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Summary for phase 1 model performance:')\n",
        "score_1 = 0\n",
        "for i in sorted(summary.keys()):\n",
        "    print('Model %d %s: %f' % (i, type(models[i]), summary[i]))\n",
        "    score_1 += summary[i]\n",
        "print('Avg score:', score_1/len(models))\n",
        "\n",
        "# Model 0 : 1.370841   KNN\n",
        "# Model 1 : 1.368519   KNN\n",
        "# Model 2 : 1.122398   LR\n",
        "# Model 3 : 0.330810   RF\n",
        "# Model 4 : 0.350650   RF\n",
        "# Model 5 : 0.505754   ET\n",
        "# Model 6 : 0.142307   XGB\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for phase 1 model performance:\n",
            "Model 0 <class 'sklearn.ensemble._forest.RandomForestClassifier'>: 0.301522\n",
            "Model 1 <class 'sklearn.ensemble._forest.RandomForestClassifier'>: 0.317112\n",
            "Model 2 <class 'xgboost.sklearn.XGBClassifier'>: 0.139199\n",
            "Model 3 <class 'xgboost.sklearn.XGBClassifier'>: 0.133411\n",
            "Model 4 <class 'lightgbm.sklearn.LGBMClassifier'>: 0.140446\n",
            "Avg score: 0.20633809638058698\n"
          ]
        }
      ],
      "execution_count": 84,
      "metadata": {
        "id": "uEt0B8fm0swb",
        "colab_type": "code",
        "outputId": "bb2df825-9353-4b99-ad08-0ee6db18f1e3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198387828,
          "user_tz": -120,
          "elapsed": 1147,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training phase 2"
      ],
      "metadata": {
        "id": "SdAXmU1r3B_y",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training phase 2\n",
        "print('Training phase 2: stacking model predictions from phase 1')\n",
        "stacking_models = []\n",
        "\n",
        "# stacking models' predictions using xgboost\n",
        "\n",
        "xgb_params = dict(objective='multi:softprob', \n",
        "              n_estimators=300,\n",
        "              colsample_bylevel=1, \n",
        "              subsample=0.9,\n",
        "              colsample_bytree=0.8, \n",
        "              gamma=0, \n",
        "              learning_rate=0.03, \n",
        "              reg_alpha=0, reg_lambda=1.5)\n",
        "\n",
        "stacking_models +=[XGBClassifier(**xgb_params)]\n",
        "\n",
        "\n",
        "\n",
        "# # stacking models' predictions using NN\n",
        "# stacking_models += [\n",
        "#                     KerasClassifier(build_fn=create_2_layer_keras_model, \n",
        "#                                     input_dim=num_models * 4, \n",
        "#                                     output_dim=4, \n",
        "#                                     nb_epoch=5, \n",
        "#                                     batch_size=256, \n",
        "#                                     verbose=0)\n",
        "#                     ]\n",
        "\n",
        "# Tune a NN with stacked features ...\n",
        "\n",
        "# stacking_models += [ build_nn_model() ]\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training phase 2: stacking model predictions from phase 1\n"
          ]
        }
      ],
      "execution_count": 81,
      "metadata": {
        "id": "Iwsz1Eux0s_Q",
        "colab_type": "code",
        "outputId": "9fcae90d-61e5-4120-ab23-f8053bb01a30",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198262675,
          "user_tz": -120,
          "elapsed": 1294,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_submission_pred = stacking_models_CV_train(stacking_models, \n",
        "                                             train_models_pred, \n",
        "                                             y, \n",
        "                                             test_models_pred, \n",
        "                                             n_classes=4, \n",
        "                                             n_folds=5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Model 0 XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
            "              learning_rate=0.03, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1.5, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.9, verbosity=1)\n",
            "Fold 0\n",
            "  logloss: 0.141453\n",
            "Fold 1\n",
            "  logloss: 0.141030\n",
            "Fold 2\n",
            "  logloss: 0.134920\n",
            "Fold 3\n",
            "  logloss: 0.132865\n",
            "Fold 4\n",
            "  logloss: 0.101952\n",
            "model average logloss: 0.130444\n"
          ]
        }
      ],
      "execution_count": 82,
      "metadata": {
        "id": "fFno-XjZ0s8q",
        "colab_type": "code",
        "outputId": "95357774-dce4-4f88-c3f5-b62269d0c041",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198310933,
          "user_tz": -120,
          "elapsed": 42872,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(models_path+'stacking_models.pickle', 'wb') as f:\n",
        "#     pickle.dump(obj=stacking_models, file=f) "
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "aVKmrN3r41VT",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avg. predictions"
      ],
      "metadata": {
        "id": "kXYJk1gp3sRM",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_submission_pred.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 85,
          "data": {
            "text/plain": [
              "(2500, 4, 1)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 85,
      "metadata": {
        "id": "8TVaaebrRfv9",
        "colab_type": "code",
        "outputId": "45a1dafc-e650-493c-86df-3157285af6ac",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198446131,
          "user_tz": -120,
          "elapsed": 1230,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_submission_pred = y_submission_pred.mean(axis=2)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "n6DQUQfi0s5y",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_submission_pred"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 87,
          "data": {
            "text/plain": [
              "array([[3.61541670e-04, 1.75162402e-04, 2.22306215e-04, 9.99240983e-01],\n",
              "       [4.51654120e-04, 9.98184347e-01, 3.97955539e-04, 9.66024504e-04],\n",
              "       [5.58877632e-04, 3.04629136e-04, 9.98546314e-01, 5.90222736e-04],\n",
              "       ...,\n",
              "       [5.40982315e-04, 2.67280260e-04, 9.98700869e-01, 4.90859873e-04],\n",
              "       [4.93156066e-04, 2.75574281e-04, 9.98663795e-01, 5.67445881e-04],\n",
              "       [2.92838548e-04, 1.73205341e-04, 4.52458195e-04, 9.99081492e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 87,
      "metadata": {
        "id": "FVA5iV654CKs",
        "colab_type": "code",
        "outputId": "3b4847d2-89f8-4883-a197-c0f4a1dcb18b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198450211,
          "user_tz": -120,
          "elapsed": 1009,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds_classes = np.argmax(y_submission_pred, axis=1)\n",
        "\n",
        "test_preds_classes.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 88,
          "data": {
            "text/plain": [
              "(2500,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 88,
      "metadata": {
        "id": "4SyENmwo9awo",
        "colab_type": "code",
        "outputId": "09e77bd2-af68-4b77-9733-93c5ac9c5479",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198455080,
          "user_tz": -120,
          "elapsed": 1167,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission"
      ],
      "metadata": {
        "id": "v7dd9mYB3k_Q",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write submission\n",
        "print(\"Write submission: averaging stacking models' predictions\")\n",
        "\n",
        "test_ids = pd.read_csv(data_path+'test.csv')['Accident_ID']\n",
        "\n",
        "submission = pd.DataFrame({'Accident_ID': test_ids,    #data_test['Accident_ID'], \n",
        "                           'Severity': np.vectorize(inverse_class_map.get)(test_preds_classes)})\n",
        "\n",
        "submission.to_csv(out_path+'submission_stack2_v2_meta_xgb_3.csv', index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write submission: averaging stacking models' predictions\n"
          ]
        }
      ],
      "execution_count": 89,
      "metadata": {
        "id": "RRCbGXvq0s0O",
        "colab_type": "code",
        "outputId": "2b5d5233-e2a7-4fde-98a2-42497f37275d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198469462,
          "user_tz": -120,
          "elapsed": 1188,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 90,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accident_ID</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Highly_Fatal_And_Damaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>Significant_Damage_And_Fatalities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14</td>\n",
              "      <td>Significant_Damage_And_Serious_Injuries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17</td>\n",
              "      <td>Highly_Fatal_And_Damaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>Significant_Damage_And_Fatalities</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accident_ID                                 Severity\n",
              "0            1                Highly_Fatal_And_Damaging\n",
              "1           10        Significant_Damage_And_Fatalities\n",
              "2           14  Significant_Damage_And_Serious_Injuries\n",
              "3           17                Highly_Fatal_And_Damaging\n",
              "4           21        Significant_Damage_And_Fatalities"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 90,
      "metadata": {
        "id": "6IVEtpcf0sl4",
        "colab_type": "code",
        "outputId": "29ade5b7-3981-4cc1-fd2d-df79807a7116",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198471961,
          "user_tz": -120,
          "elapsed": 877,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission.Severity.value_counts(normalize=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 91,
          "data": {
            "text/plain": [
              "Highly_Fatal_And_Damaging                  0.3044\n",
              "Minor_Damage_And_Injuries                  0.2748\n",
              "Significant_Damage_And_Serious_Injuries    0.2560\n",
              "Significant_Damage_And_Fatalities          0.1648\n",
              "Name: Severity, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 91,
      "metadata": {
        "id": "ZodAcwdY0siB",
        "colab_type": "code",
        "outputId": "9fc39ceb-c912-4856-d5ab-26e6e3ee222f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581198477980,
          "user_tz": -120,
          "elapsed": 1079,
          "user": {
            "displayName": "Ioannis Meintanis",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCevv-cLcyYJGYOs5F9dioLstXWUj1C480AXa_Z=s64",
            "userId": "13658737335839172040"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test saved model for reproducibility"
      ],
      "metadata": {
        "id": "QxlyIfwiKhog",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # load LGBM model\n",
        "# with open(models_path+'lgbm2_22f_v1_model.pickle', 'rb') as f:\n",
        "#     lgb_model = pickle.load(f) "
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "fe8BPrBTcZFx",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_data = data_test[feats].values\n",
        "\n",
        "# test_preds_classes = lgb_model.predict(test_data, num_iteration=lgb_model.best_iteration_)\n",
        "# print(test_preds_classes.shape)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "ASqluGkJKk0W",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  test_ids = pd.read_csv(data_path+'test.csv')['Accident_ID']\n",
        "\n",
        "# submission = pd.DataFrame({'Accident_ID': test_ids,      # data_test['Accident_ID'], \n",
        "#                            'Severity': np.vectorize(inverse_class_map.get)(test_preds_classes)})\n",
        "\n",
        "# submission.to_csv(out_path+'submission_test_lgbm_v1_10f.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "G-sSLov-Kzg4",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submission.head()"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "iXvtNSqsLO1r",
        "colab_type": "code",
        "colab": {}
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Hacker: 2-layer stacking.ipynb",
      "provenance": [
        {
          "file_id": "1idO8bEpVg1iMNwQmQHfj80WLA_dnzHsP",
          "timestamp": 1581114399222
        }
      ],
      "collapsed_sections": [
        "4wUJcsWCnOu8"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP6MXpnNcY6ME7CcbloQRNL"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}